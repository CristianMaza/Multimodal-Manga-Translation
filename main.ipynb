{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, client, max_tokens=200, temperature=2, top_p=0.9):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': question,\n",
    "            }\n",
    "        ],\n",
    "        model='llama3',\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=False\n",
    "    )\n",
    "    answer = chat_completion.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "def evaluate_model(client, test_dataset, prompt):\n",
    "    data = []\n",
    "    references = []\n",
    "    for example in tqdm(test_dataset, desc=\"Evaluating\"):\n",
    "        sentence = example['text_ja']\n",
    "        ground_truth = example['text_en']\n",
    "        predicted_translation = translate_llm(sentence, prompt, client)\n",
    "        data.append({\n",
    "            'sentence': sentence,\n",
    "            'ground_truth': ground_truth,\n",
    "            'predicted_translation': predicted_translation\n",
    "        })\n",
    "        references.append(ground_truth)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    bleu = calculate_bleu(df['predicted_translation'].tolist(), references)\n",
    "    return df, bleu\n",
    "\n",
    "def translate_llm(sentence, prompt, client):\n",
    "    question = prompt.format(text=sentence)\n",
    "    answer = ask_question(question, client)\n",
    "    \n",
    "    # Split the answer into parts based on the \"Translation:\" keyword\n",
    "    parts = answer.split(\"Translation:\")\n",
    "    if len(parts) > 1:\n",
    "        # Extract the translations from the last part\n",
    "        translations = parts[-1].strip()\n",
    "        \n",
    "        # Split the translations into sentences\n",
    "        sentences = translations.split(\"\\n\")\n",
    "        \n",
    "        # Initialize an empty list to store the translated sentences\n",
    "        translated_sentences = []\n",
    "        \n",
    "        # Iterate over each sentence\n",
    "        for sentence in sentences:\n",
    "            # Check if the sentence starts with a number followed by a dot and a space\n",
    "            if sentence.strip() and sentence.split(\". \", 1)[0].isdigit():\n",
    "                # Remove the number and dot from the beginning of the sentence\n",
    "                sentence = sentence.split(\". \", 1)[1].strip()\n",
    "            \n",
    "            # Append the processed sentence to the list of translated sentences\n",
    "            translated_sentences.append(sentence)\n",
    "        \n",
    "        # Join the translated sentences into a single string\n",
    "        translated_text = \"\\n\".join(translated_sentences)\n",
    "    else:\n",
    "        # No \"Translation:\" keyword found, return the original answer\n",
    "        translated_text = answer.strip()\n",
    "    \n",
    "    #print(translated_text)\n",
    "    return translated_text\n",
    "\n",
    "def calculate_bleu(predictions, references):\n",
    "    reference_corpus = [[ref.split()] for ref in references]\n",
    "    prediction_corpus = [pred.split() for pred in predictions]\n",
    "    \n",
    "    # Create a smoothing function\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    bleu4 = corpus_bleu(reference_corpus, prediction_corpus, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "    return bleu4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data\n",
    "with open(r\".\\open-mantra-dataset\\annotation.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the testing set\n",
    "test_dataset = []\n",
    "for book in data:\n",
    "    for page in book[\"pages\"]:\n",
    "        for text in page[\"text\"]:\n",
    "            if \"text_ja\" in text and \"text_en\" in text:\n",
    "                test_dataset.append({\n",
    "                    \"text_ja\": text[\"text_ja\"],\n",
    "                    \"text_en\": text[\"text_en\"]\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the prompt for translation\n",
    "prompt_baseline = \"\"\"You are a translator from Japanese to English. \n",
    "Some rules to remember:\n",
    "\n",
    "Maintaining the contents' accuracy is important, but since texts are from manga, we want to prioritize naturalness and ease of communication.\n",
    "Instead of translating word by word, try to translate the whole sentence or phrase at once.\n",
    "Number of translated sentences should be the same as the number of input sentences.\n",
    "Return translations without additional explanations, comments, notes or interactions. Simply use the format for translations.\n",
    "\n",
    "Here's the format.\n",
    "\n",
    "Input:\n",
    "1. Sentence in Japanese\n",
    "\n",
    "Translation:\n",
    "1. Translation in English\n",
    "\n",
    "Input:\n",
    "1. {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1592/1592 [10:35<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 2.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subset = test_dataset[:5]\n",
    "\n",
    "# ollama running on local\n",
    "client = OpenAI(base_url='http://localhost:11434/v1/', api_key='ollama')\n",
    "df, bleu4 = evaluate_model(client, test_dataset, prompt_baseline)\n",
    "print(f\"BLEU Score: {bleu4*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>predicted_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>綴じ眼のシオラ</td>\n",
       "      <td>bound eye siora</td>\n",
       "      <td>Siola of Twined Eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>朽鷹みつき</td>\n",
       "      <td>Mitsuki Kuchitaka</td>\n",
       "      <td>Sparrowhawk's Whisker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>だからっ</td>\n",
       "      <td>I'm telling you!!</td>\n",
       "      <td>So then!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>知らないって言ってるだろっ</td>\n",
       "      <td>I don't know what you're talking about!</td>\n",
       "      <td>So you're saying you don't know?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>そんな借金なんて!</td>\n",
       "      <td>i don't owe you!</td>\n",
       "      <td>Don't even mention that debt!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>こりゃかなわん</td>\n",
       "      <td>you beat me</td>\n",
       "      <td>Don't expect me to get it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>さて</td>\n",
       "      <td>well!\\n</td>\n",
       "      <td>Well, then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>さて明日は墓掃除だ!</td>\n",
       "      <td>tomorrow we clean the graves!</td>\n",
       "      <td>Ah, tomorrow's the graveyard cleanup, I guess!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>こ、こら</td>\n",
       "      <td>hey!!!</td>\n",
       "      <td>Geez!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>急に走るな!</td>\n",
       "      <td>don't start running all of a sudden!</td>\n",
       "      <td>Don't run away so fast!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence                             ground_truth  \\\n",
       "0           綴じ眼のシオラ                          bound eye siora   \n",
       "1             朽鷹みつき                        Mitsuki Kuchitaka   \n",
       "2              だからっ                        I'm telling you!!   \n",
       "3     知らないって言ってるだろっ  I don't know what you're talking about!   \n",
       "4         そんな借金なんて!                         i don't owe you!   \n",
       "...             ...                                      ...   \n",
       "1587        こりゃかなわん                              you beat me   \n",
       "1588             さて                                  well!\\n   \n",
       "1589     さて明日は墓掃除だ!            tomorrow we clean the graves!   \n",
       "1590           こ、こら                                   hey!!!   \n",
       "1591         急に走るな!     don't start running all of a sudden!   \n",
       "\n",
       "                               predicted_translation  \n",
       "0                               Siola of Twined Eyes  \n",
       "1                              Sparrowhawk's Whisker  \n",
       "2                                           So then!  \n",
       "3                   So you're saying you don't know?  \n",
       "4                      Don't even mention that debt!  \n",
       "...                                              ...  \n",
       "1587                      Don't expect me to get it!  \n",
       "1588                                     Well, then.  \n",
       "1589  Ah, tomorrow's the graveyard cleanup, I guess!  \n",
       "1590                                           Geez!  \n",
       "1591                         Don't run away so fast!  \n",
       "\n",
       "[1592 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
